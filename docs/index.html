<!DOCTYPE html>
<html>

<head lang="en">
  <!-- <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> -->

  <!-- <meta http-equiv="x-ua-compatible" content="ie=edge"> -->

  <title>PEANUT: Predicting and Navigating to Unseen Targets</title>

  <meta name="description" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- mirror: F0%9F%AA%9E&lt -->

  <link rel="stylesheet" type="text/css" href="./files/slick.css">
  <link rel="stylesheet" type="text/css" href="./files/slick-theme.css">
  <link rel="stylesheet" href="./files/bulma.min.css">
  <link rel="stylesheet" href="./files/bulma-slider.min.css">
  <link rel="stylesheet" href="./files/bulma-carousel.min.css">
  <link rel="stylesheet" href="./files/bootstrap.min.css">
  <link rel="stylesheet" href="./files/font-awesome.min.css">
  <link rel="stylesheet" href="./files/codemirror.min.css">
  <link rel="stylesheet" href="./files/app.css">
  <link rel="stylesheet" href="./files/index.css">
  <link rel="stylesheet" href="./files/select.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./files/bootstrap.min.js"></script>
  <script src="./files/codemirror.min.js"></script>
  <script src="./files/clipboard.min.js"></script>
  <script src="./files/video_comparison.js"></script>
  <script src="./files/select.js"></script>
  <script src="./files/bulma-slider.min.js"></script>
  <script src="./files/bulma-carousel.min.js"></script>
  <!-- <script src="./files/app.js"></script> -->
  <script src="./files/index.js"></script>
  <!-- <script src="./files/slick.js"></script> -->

</head>

<body>
  <div class="container" id="header" style="text-align: center; margin: auto;">
    <div class="row" id="title-row" style="max-width: 100%; margin: 0 auto; display: inline-block">
      <h2 class="col-md-12 text-center" id="title">
        <b>PEANUT</b>: Predicting and Navigating to Unseen Targets

      </h2>
      <h2 class="col-md-12 text-center" id="venue" style="font-size:1.5em; margin-top: 0">
        ICCV 2023
      </h2>
    </div>
  </div>
  <script>
  </script>
  <div class="container" id="main">
    <div class="row">
      <div class="col-sm-10 col-sm-offset-1 text-center">
        <ul class="list-inline">
          <li> <a href="https://ajzhai.github.io/">Albert J. Zhai</a> </li>
          <li> <a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a> </li>
        </ul>
        <ul class="list-inline">
          <li> University of Illinois at Urbana-Champaign </li>
        </ul>
      </div>
    </div>

    <div class="row">
      <div class="col-sm-8 col-sm-offset-2 text-center">
        <span class="link-block">
          <a href="https://arxiv.org/abs/2212.02497" class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas"
                data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"
                data-fa-i2svg="">
                <path fill="currentColor"
                  d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z">
                </path>
              </svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
            </span>
            <span>Paper</span>
          </a>
        </span>
        <span class="link-block">
          <a href="https://github.com/ajzhai/PEANUT" class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab"
                data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg="">
                <path fill="currentColor"
                  d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                </path>
              </svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
            </span>
            <span>Code</span>
          </a>
        </span>
      </div>
    </div>


    <div class="row">
      <div class="col-sm-10 col-sm-offset-1 text-center">
        <br>
        <video id="firstvid" width="100%" controls playsinline="" autoplay="" loop="" muted=""
        poster="files/loading.gif">
          <source src="files/vids/web_vid8.mp4" type="video/mp4">
        </video>
        <br>
      </div>
      
    </div>


    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Abstract
        </h3>
        <div class="text-justify">
          Efficient ObjectGoal navigation (ObjectNav) in novel environments requires an understanding of the spatial and semantic regularities in environment layouts.
          In this work, we present a straightforward method for learning these regularities by predicting the locations of unobserved objects from incomplete semantic maps. 
          Our method differs from previous prediction-based navigation methods, such as frontier potential prediction or egocentric map completion, 
          by directly predicting unseen targets while leveraging the global context from all previously explored areas.
          Our prediction model is lightweight and can be trained in a supervised manner using a relatively small amount of passively collected data. 
          Once trained, the model can be incorporated into a modular pipeline for ObjectNav without the need for any reinforcement learning. 
          We validate the effectiveness of our method on the HM3D and MP3D ObjectNav datasets. We find that it achieves the state-of-the-art on both datasets, 
          despite not using any additional data for training. 
        </div>
        <br>
        <center>
          <img src="./files/images/overview.png" class="img-responsive" alt="overview" width="100%"
            style="max-height: 450px;margin:auto;">
        </center>
        <br>
      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Predicting Unseen Objects
        </h3>
        <div class="text-justify">
          We visualize predictions made by our model in scenes from the val split of the Habitat-Matterport3D (HM3D) dataset. 
          The top row shows the agent's RGB observation, and the bottom row shows the incomplete semantic map overlaid with the target probability prediction. 
          Note that the prediction network only has access to the semantic map, not the RGB images.
        </div>
        <br>
        <center>
          <img src="./files/images/preds.png" class="img-responsive" alt="overview" width="100%"
            style="margin:auto;">
        </center>
      </div>
    </div>

    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Example ObjectNav Episodes
        </h3>
        <div class="text-justify">
          We visualize example episodes of ObjectNav using PEANUT on the HM3D (val). The left panel shows the agent's RGB observation. 
          The center panel shows the agent's semantic map overlaid with its target predictions heatmap, which is updated every ten steps.
          The top right panel visualizes the distance-based weighting factor, 
          which is used to encourage the agent to search in closer areas before moving on to farther areas.
          The bottom right panel shows the final value map, from which we take the argmax for goal selection.
        </div>
        <br>

          <video id="vid2" width="100%" controls playsinline=""  muted=""
          >
          <source src="files/vids/supp_vid2.mp4" type="video/mp4">
        </video>
        <br>
        <video id="vid5" width="100%" controls playsinline=""  muted=""
        >
          <source src="files/vids/supp_vid5.mp4" type="video/mp4">
        </video>
        <!-- <video id="vid6" width="50%" playsinline=""  muted=""
          poster="files/loading.gif">
          <source src="files/vids/supp_vid8.mp4" type="video/mp4">
        </video> -->
        <br>
        <video id="vid19" width="100%" controls playsinline=""   muted=""
          >
          <source src="files/vids/supp_vid19.mp4" type="video/mp4">
        </video>
        <br> <br>
      </div>
    </div>
<!-- 
    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          References
        </h3>
        <ol>
          <li>
            Victor Schmidt, Alexandra Sasha Luccioni, M ́elisande Teng, Tianyu Zhang, Alexia Reynaud,
            Sunand Raghupathi, Gautier Cosne,
            Adrien Juraver, Vahe Vardanyan, Alex Hernandez-Garcia, Yoshua Bengio.
            Climategan: Raising climate change awareness by generating images of floods. ICLR, 2022.
            <a href="https://github.com/cc-ai/climategan">[code]</a>
          </li>
          <li>
            Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj ̈orn Ommer.
            High-resolution image synthesis with latent diffusion models. In CVPR, 2022.
            <a href="https://github.com/CompVis/stable-diffusion">[code]</a>
          </li>
          <li>
            Taesung Park, Jun-Yan Zhu, Oliver Wang, Jingwan Lu, Eli Shechtman, Alexei Efros, and Richard
            Zhang.
            Swapping autoencoder for deep image manipulation. NeurIPS, 2020.
            <a href="https://github.com/taesungp/swapping-autoencoder-pytorch">[code]</a>
          </li>
        </ol>
      </div>
    </div> -->
    <div class="row">
      <div class="col-md-10 col-md-offset-1">
        <h3>
          Acknowledgements
        </h3>

        The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and 
        <a  href="https://climatenerf.github.io">ClimateNeRF</a>.
        <br>

      </div>
    </div>
  </div>
</body>

</html>